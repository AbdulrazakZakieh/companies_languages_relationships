# -*- coding: utf-8 -*-
"""Untitled27.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u1alDb0NCjRiymRaOrUxY48YRdEReNN0
"""

import json
import tarfile
from os import listdir
from os.path import isfile, join
from pathlib import Path
import warnings

warnings.filterwarnings("ignore")

def load_dataset(dataset_name, uncompressed_folder_name):
  """Loading dataset from compressed file

  Uncompress the provided dataset, and return the json files
  from the uncompressed folder.

  Parameters
  ----------
  path: str
    The compressed dataset name, in the same directory as the script

  uncompressed_folder_name: str
    The name of the inside uncompressed folder

  """
  script_dir = Path(__file__).parent
  dataset_file = script_dir  / dataset_name
  dataset_path = dataset_file.absolute()
  file = tarfile.open(dataset_path)
  extraction_folder = script_dir / "extracted-profiles"
  extraction_folder.mkdir(parents=True, exist_ok=True)
  file.extractall(extraction_folder)
  file.close()

  profiles_path = extraction_folder / uncompressed_folder_name
  profiles_paths = [f for f in listdir(profiles_path) if isfile(join(profiles_path, f))]
  profiles = []
  for profile in profiles_paths:
    with open(profiles_path / profile) as json_file:
      data = json.load(json_file)
      profiles.append(data)
  return profiles

def filter_dataset_numerically(profiles, filter):
  """Filter the dataset.

  Filter the dataset based on the count of the provided feature.

  Parameters
  ----------
  profiles: list
    List of dictionaries

  filter: dict
    Dictionary with the following keys:
      count: int
        The count to filter on
      minimum: boolean
        True to filter the minimum count, False to filter the maximum count
      feature: str
        Feature to use in filtering
  """

  filtered_profiles = []
  for profile in profiles:
    if filter['minimum']:
      if len(profile[filter['feature']]) >= filter['count']:
        filtered_profiles.append(profile)
    else:
      if len(profile[filter['feature']]) <= filter['count']:
        filtered_profiles.append(profile)
  return filtered_profiles

def extract_feature(profiles, feature):
  """ Extract a feature from the dataset

  Makes a set out of extracted features from the dataset.

  Parameters
  ----------
  profiles: list
    List of dictionaries

  feature: str
    Feature to extract
  """

  features = set()
  for profile in profiles:
    for value in profile[feature]:
      features.add(value)
  return features

def calculate_probability(profiles, value, feature):
  """ Calculate the probability of a value in the dataset

  Parameters
  ----------
  profiles: list
    List of dictionaries

  value: any
    Value to calculate the probability for

  feature: str
    Feature we are calculating the probability for
  """

  count = 0
  for profile in profiles:
    if value in profile[feature]:
      count += 1
  return count / len(profiles)

def calculate_set_probability(profiles, data, feature):
  """ Calculate the probability of a set of values in the dataset

  Parameters
  ----------
  profiles: list
    List of dictionaries

  data: set
    Set of values to calculate the probability for

  feature: str
    Feature we are calculating the probability for
  """

  probabilities = {}
  for value in data:
    probabilities[value] = calculate_probability(profiles, value, feature)
  return probabilities

def calculate_intersection_probability(profiles, value1, feature1, value2, feature2):
  """ Calculate the probability of an intersection of two values in the dataset

  Parameters
  ----------
  profiles: list
    List of dictionaries

  value1: any
    The first value to calculate the instersection probability

  feature1: str
    The first feature we are calculating the instersection probability

  value2: any
    The second value to calculate the instersection probability

  feature2: str
    The second feature we are calculating the instersection probability

  """

  count = 0
  for profile in profiles:
    if value1 in profile[feature1] and value2 in profile[feature2]:
      count += 1
  return count / len(profiles)

def calculate_conditional_probabilities(profiles, first_feature_values, first_feature, second_feature_values, second_feature):
  """ Calculate the conditional probabilities in the dataset

  Calculates the conditional probabilities for each pair of the provided values
  in the dataset.

  Parameters
  ----------
  profiles: list
    List of dictionaries

  first_feature_values: set
    Set of values to calculate the conditional probability for

  first_feature: str
    The first feature we are calculating the conditional probability for

  second_feature_values: set
    Set of values to calculate the conditional probability for

  second_feature: str
    The second feature we are calculating the conditional probability for
  """

  companies_probabilities = calculate_set_probability(profiles, second_feature_values, second_feature)
  intesection_probabilities = {}
  conditional_probabilities = {}
  for first_feature_value in first_feature_values:
    for second_feature_value in second_feature_values:
      intersection_probability = calculate_intersection_probability(profiles, first_feature_value, first_feature, second_feature_value, second_feature)
      conditional_probabilities[(first_feature_value, second_feature_value)] = intersection_probability / companies_probabilities[second_feature_value]
  return conditional_probabilities

def print_results(results):
  """ Print the results in the required format
  """

  for result in results:
    print("P({},{}) = {}".format(result[0], result[1], results[result]))

def investigate_relationship(profiles, filter, first_feature, second_feature):
  """ Investigate the relationship between the two features.

  The function filters the provided dataset. Extracts the two required features
  from the filtered profiles, then calculates the conditional
  probabilities and prints the results.

  Parameters
  ----------
  profiles: list
    List of dictionaries

  filter: dict
    Dictionary with the following keys:
      count: int
        The count to filter on
      minimum: boolean
        True to filter the minimum count, False to filter the maximum count
      feature: str
        Feature to use in filtering


  first_feature: str
    The first feature to investigage

  second_feature: str
    The second feature to investigage
  """

  filtered_profiles = filter_dataset_numerically(profiles, filter)
  first_feature_values = extract_feature(filtered_profiles, first_feature)
  second_feature_values = extract_feature(filtered_profiles, second_feature)
  results = calculate_conditional_probabilities(filtered_profiles, first_feature_values, first_feature, second_feature_values, second_feature)
  print_results(results)

profiles = load_dataset('profiles.tar.gz','profiles')
filter = {'count':3, 'minimum':True, 'feature':'companies'}
count=3
minimum=True
first_feature = 'skills'
second_feature = 'companies'
investigate_relationship(profiles, filter, first_feature, second_feature)

